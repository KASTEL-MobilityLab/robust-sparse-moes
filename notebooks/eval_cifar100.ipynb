{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import List\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from src.utils.wandb import get_runs\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "\n",
    "def lmap(*x):\n",
    "    return list(map(*x))\n",
    "\n",
    "\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Project is specified by <entity/project-name>\n",
    "runs = get_runs(project=\"robust-cifar100-resnet-moe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "runs[1].summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "summary_list, config_list, name_list = [], [], []\n",
    "for run in runs:\n",
    "    # .summary contains the output keys/values for metrics like accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_list.append(run.summary._json_dict)\n",
    "\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config_list.append({k: v for k, v in run.config.items() if not k.startswith(\"_\")})\n",
    "\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "runs_df = pd.DataFrame({\"summary\": summary_list, \"config\": config_list, \"name\": name_list})\n",
    "# runs_df.to_csv(\"project.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(runs_df[\"summary\"])\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_idx = name_list.index(\"cifar100-resnet18\")\n",
    "summary = pd.DataFrame(runs_df[\"summary\"][run_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "runs_df[\"summary\"][run_idx][\"train/acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "summary[\"train/acc\"][\"values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_names = [\n",
    "    \"cifar100-resnet18\",\n",
    "    \"cifar100-resnet18-block-moe4-GALRN-1\",\n",
    "    \"cifar100-resnet18-block-moe4-CGARN-1\",\n",
    "    \"cifar100-resnet18-conv-moe4-GALRN-1\",\n",
    "    \"cifar100-resnet18-conv-moe4-CGARN-1\",\n",
    "]\n",
    "short_run_names = [\n",
    "    rn.replace(\"cifar100-resnet18-\", \"*-\").replace(\"cifar100-resnet18\", \"resnet18\")\n",
    "    for rn in run_names\n",
    "]\n",
    "\n",
    "free_adv_run_names = [\n",
    "    \"cifar100-resnet18-free-adv\",\n",
    "    \"cifar100-resnet18-free-adv-train-block-moe4-GALRN-1\",\n",
    "    \"cifar100-resnet18-free-adv-train-block-moe4-CGARN-1\",\n",
    "    \"cifar100-resnet18-free-adv-train-conv-moe4-GALRN-1\",\n",
    "    \"cifar100-resnet18-free-adv-train-conv-moe4-CGARN-1\",\n",
    "]\n",
    "\n",
    "\n",
    "def _summary_for_name(run_name):\n",
    "    return runs_df[\"summary\"][name_list.index(run_name)]\n",
    "\n",
    "\n",
    "def lmap(*x):\n",
    "    return list(map(*x))\n",
    "\n",
    "\n",
    "summaries = lmap(_summary_for_name, run_names)\n",
    "free_adv_summaries = lmap(_summary_for_name, free_adv_run_names)\n",
    "\n",
    "test_accs = [summary[\"test/acc\"] for summary in summaries]\n",
    "adversarial_accs = [summary[\"attack/acc\"] for summary in summaries]\n",
    "\n",
    "fa_test_accs = [summary[\"test/acc\"] for summary in free_adv_summaries]\n",
    "fa_adversarial_accs = [summary[\"attack/acc\"] for summary in free_adv_summaries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    data=zip(test_accs, fa_test_accs, adversarial_accs, fa_adversarial_accs),\n",
    "    index=short_run_names,\n",
    "    columns=[\"Natural\", \"Free-Adv-Train\", \"PGD(20,8,2)\", \"Free-Adv-Train, PGD(20,8,2)\"],\n",
    ")\n",
    "fmts_max_4f = {\n",
    "    column: partial(bold_formatter, value=df[column].max(), num_decimals=4)\n",
    "    for column in df.columns\n",
    "}\n",
    "print(df.to_latex(formatters=fmts_max_4f, escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cfgs = [\n",
    "    \"cifar100-resnet18-block-moe4-GALRN\",\n",
    "    \"cifar100-resnet18-block-moe4-CGARN\",\n",
    "    \"cifar100-resnet18-conv-moe4-GALRN\",\n",
    "    \"cifar100-resnet18-conv-moe4-CGARN\",\n",
    "]\n",
    "\n",
    "ks = lmap(str, range(1, 5))\n",
    "\n",
    "\n",
    "def names_for_cfg(cfg):\n",
    "    # cfg = cfg.replace(\"18\",\"18-free-adv-train\")\n",
    "    return [f\"{cfg}-{k}\" for k in ks]\n",
    "\n",
    "\n",
    "def summaries_for_cfg(cfg):\n",
    "    names = names_for_cfg(cfg)\n",
    "    return lmap(_summary_for_name, names)\n",
    "\n",
    "\n",
    "def accs_for_cfg(cfg, key=\"attack/acc\"):\n",
    "    summaries = summaries_for_cfg(cfg)\n",
    "    accs = [summary[key] for summary in summaries]\n",
    "    return accs\n",
    "\n",
    "\n",
    "accs = lmap(accs_for_cfg, cfgs)\n",
    "accs_test = lmap(partial(accs_for_cfg, key=\"test/acc\"), cfgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "baseline = _summary_for_name(\"cifar100-resnet18\")[\"attack/acc\"]\n",
    "columns = [\"baseline\", *ks]\n",
    "data = [[baseline, None, None, None, None], *([None, *d] for d in accs)]\n",
    "index = [\"cifar100-resnet18\", *cfgs]\n",
    "index = [\n",
    "    rn.replace(\"cifar100-resnet18-\", \"*-\").replace(\"cifar100-resnet18\", \"resnet18\") for rn in index\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=data,\n",
    "    index=index,\n",
    "    columns=columns,\n",
    ")\n",
    "fmts_max_4f = {\n",
    "    column: partial(bold_formatter, value=baseline + 1e-4, num_decimals=4) for column in df.columns\n",
    "}\n",
    "print(df.to_latex(formatters=fmts_max_4f, escape=False, na_rep=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "baseline = _summary_for_name(\"cifar100-resnet18\")[\"test/acc\"]\n",
    "columns = [\"baseline\", *ks]\n",
    "data = [[baseline, None, None, None, None], *([None, *d] for d in accs_test)]\n",
    "index = [\"cifar100-resnet18\", *cfgs]\n",
    "index = [\n",
    "    rn.replace(\"cifar100-resnet18-\", \"*-\").replace(\"cifar100-resnet18\", \"resnet18\") for rn in index\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=data,\n",
    "    index=index,\n",
    "    columns=columns,\n",
    ")\n",
    "fmts_max_4f = {\n",
    "    column: partial(bold_formatter, value=baseline + 1e-4, num_decimals=4) for column in df.columns\n",
    "}\n",
    "print(df.to_latex(formatters=fmts_max_4f, escape=False, na_rep=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df.T.plot()\n",
    "plt.savefig(\"ks_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_to_pred_table(run):\n",
    "    return wandb.use_artifact(f\"run-{run.id}-prediction_table:v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_to_pred_table(runs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fixed experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_idx = name_list.index(\"evaluate-cifar100-resnet18-pgd-adv-train-block-moe16-CGARN-1\")\n",
    "summary = pd.DataFrame(runs_df[\"summary\"][run_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "summary[\"performance_plot_PGD-20-8-2_table\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pp_table = runs[run_idx].summary[\"performance_plot_PGD-20-8-2_table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dict(pp_table.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./cifar100_fixed_experts_robust/wandb_fixed_expert_pgd_perf_16.csv\")\n",
    "\n",
    "\n",
    "def load_fixed_expert_file(fp):\n",
    "    df = pd.read_csv(fp)\n",
    "    accs = df[\"Metric\"].values\n",
    "    all_experts_acc = accs[-1]\n",
    "    fe_accs = accs[:-1]\n",
    "    return all_experts_acc, fe_accs\n",
    "\n",
    "\n",
    "def load_expert_files(\n",
    "    num_experts: list, prefix=\"cifar100_fixed_experts_robust/wandb_fixed_expert_pgd_perf\"\n",
    "):\n",
    "    accs = []\n",
    "    fe_accs_list = []\n",
    "    for ne in num_experts:\n",
    "        all_experts_acc, fe_accs = load_fixed_expert_file(f\"./{prefix}_{ne}.csv\")\n",
    "        accs.append(all_experts_acc)\n",
    "        fe_accs_list.append(fe_accs)\n",
    "    return accs, fe_accs_list\n",
    "\n",
    "\n",
    "def match_fixed_expert_accuracies(num_experts_list, fe_accs_list):\n",
    "    fe_data = [\n",
    "        (num_experts, fe_acc)\n",
    "        for num_experts, fe_accs in zip(num_experts_list, fe_accs_list)\n",
    "        for fe_acc in fe_accs\n",
    "    ]\n",
    "    return np.array(fe_data, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_fixed_experts(\n",
    "    num_experts_list,\n",
    "    accs,\n",
    "    fe_data_np,\n",
    "    fe_data_brown_np=None,\n",
    "    show_accs=True,\n",
    "    show_fe_scatter=True,\n",
    "    show_sota=False,\n",
    "    ylabel=\"Adversarial Accuracy\",\n",
    "    baseline=0.178,\n",
    "):\n",
    "    np.random.seed(1)\n",
    "\n",
    "    plt.xticks(num_experts_list)\n",
    "    # plt.xlim(1.5,max(num_experts_list)+1)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(\"Number of Experts\")\n",
    "\n",
    "    legend = [\"ResNet18 Baseline\"]\n",
    "    plt.axhline(baseline, color=\"green\", linestyle=\"--\")\n",
    "    (accs_line,) = plt.plot(num_experts_list, accs, marker=\"x\")\n",
    "\n",
    "    if show_accs:\n",
    "        legend.append(\"ResNet18-BlockMoE; k=1\")\n",
    "    else:\n",
    "        accs_line.remove()\n",
    "\n",
    "    if show_fe_scatter and len(fe_data_np) > 0:\n",
    "        fe_data_np = np.copy(fe_data_np)\n",
    "        fe_data_np[:, 0] += fe_data_np[:, 0] * np.random.uniform(\n",
    "            -0.1, 0.1, size=fe_data_np.shape[0]\n",
    "        )\n",
    "        sns.scatterplot(x=fe_data_np[:, 0], y=fe_data_np[:, 1], color=\"brown\")\n",
    "        legend.append(\"Fixed Expert (robust)\")\n",
    "\n",
    "    if show_fe_scatter and fe_data_brown_np is not None and len(fe_data_brown_np) > 0:\n",
    "        fe_data_brown_np = np.copy(fe_data_brown_np)\n",
    "        fe_data_brown_np[:, 0] += fe_data_brown_np[:, 0] * np.random.uniform(\n",
    "            -0.1, 0.1, size=fe_data_brown_np.shape[0]\n",
    "        )\n",
    "        sns.scatterplot(x=fe_data_brown_np[:, 0], y=fe_data_brown_np[:, 1])\n",
    "        legend.append(\"Fixed Expert\")\n",
    "\n",
    "    if show_sota:\n",
    "        plt.axhspan(0.25, 0.27, color=\"red\", linestyle=\"--\", alpha=0.3)\n",
    "        legend.append(\"ResNet18 SOTA\")\n",
    "\n",
    "    plt.legend(legend)\n",
    "    plt.semilogx(base=2)\n",
    "    # plt.ylim(0.05, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "prefix = \"cifar100_fixed_experts_robust/wandb_fixed_expert_pgd_perf\"\n",
    "prefix_natural = \"cifar100_fixed_experts_robust/wandb_fixed_expert_natural_perf\"\n",
    "figure_prefix = \"cifar_robust\"\n",
    "\n",
    "num_experts_list = [2, 4, 8, 16, 32]\n",
    "accs, fe_accs_list = load_expert_files(num_experts_list, prefix=prefix)\n",
    "accs_natural, fe_accs_natural_list = load_expert_files(num_experts_list, prefix=prefix_natural)\n",
    "\n",
    "fe_data_np = match_fixed_expert_accuracies(num_experts_list, fe_accs_list)\n",
    "\n",
    "fe_data_natural_np = match_fixed_expert_accuracies(num_experts_list, fe_accs_natural_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accs_np = np.array([accs[num_experts_list.index(x)] for x in fe_data_np[:, 0]])\n",
    "accs_up = fe_data_np[:, 1] >= accs_np\n",
    "fe_data_up = fe_data_np[accs_up]\n",
    "fe_data_down = fe_data_np[~accs_up]\n",
    "\n",
    "fe_data_natural_up = fe_data_natural_np[accs_up]\n",
    "fe_data_natural_down = fe_data_natural_np[~accs_up]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_fixed_experts(\n",
    "    num_experts_list,\n",
    "    accs,\n",
    "    fe_data_up,\n",
    "    fe_data_brown_np=fe_data_down,\n",
    "    show_fe_scatter=True,\n",
    "    show_sota=False,\n",
    ")\n",
    "plt.savefig(f\"{figure_prefix}_adv_fixed_expert_plot.png\")\n",
    "plt.show()\n",
    "\n",
    "plot_fixed_experts(\n",
    "    num_experts_list,\n",
    "    accs_natural,\n",
    "    fe_data_natural_up,\n",
    "    fe_data_brown_np=fe_data_natural_down,\n",
    "    show_fe_scatter=True,\n",
    "    show_sota=False,\n",
    "    ylabel=\"Accuracy\",\n",
    "    baseline=0.5232,\n",
    ")\n",
    "plt.savefig(f\"{figure_prefix}_natural_fixed_expert_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pp_table = runs[1].summary[\"performance_plot_PGD-20-8-2_table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "run = wandb.init(project=\"robust-cifar100-resnet-moe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "my_table = wandb.use_artifact(\"run-2meisvnp-loss_plot_PGD2082_table:v0\").get(\n",
    "    \"loss_plot_PGD-20-8-2_table.table.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "my_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_fixed_expert_table(table, column=\"Metric\"):\n",
    "    accs = table.get_column(column)\n",
    "    all_experts_acc = accs[-1]\n",
    "    fe_accs = accs[:-1]\n",
    "    return all_experts_acc, fe_accs\n",
    "\n",
    "\n",
    "def get_table(artifact_run, table_names):\n",
    "    if isinstance(table_names, str):\n",
    "        table_names = [table_names]\n",
    "    id = artifact_run.id\n",
    "    for table_name in table_names:\n",
    "        try:\n",
    "            short_table_name = table_name.replace(\"-\", \"\")\n",
    "            my_table = wandb.use_artifact(f\"run-{id}-{short_table_name}:v0\").get(\n",
    "                f\"{table_name}.table.json\"\n",
    "            )\n",
    "            return my_table\n",
    "        except Exception as e:\n",
    "            print(f\"Ignoring error: {e}\")\n",
    "    raise ValueError(\"None of the given tables could be found!\")\n",
    "\n",
    "\n",
    "def load_expert_accs(runs: list, table_names=\"loss_plot_PGD-20-8-2_table\", column=\"Metric\"):\n",
    "    accs = []\n",
    "    fe_accs_list = []\n",
    "    for run in runs:\n",
    "        table = get_table(run, table_names)\n",
    "        all_experts_acc, fe_accs = load_fixed_expert_table(table, column=column)\n",
    "        accs.append(all_experts_acc)\n",
    "        fe_accs_list.append(fe_accs)\n",
    "    return accs, fe_accs_list\n",
    "\n",
    "\n",
    "def fixed_expert_performance_plots(runs, figure_prefix, baseline_natural, baseline_attacked):\n",
    "    accs_list, fe_accs_list = load_expert_accs(\n",
    "        runs, table_names=(\"performance_plot_natural_table\", \"loss_plot_natural_table\")\n",
    "    )\n",
    "    accs_robust_list, fe_accs_robust_list = load_expert_accs(\n",
    "        runs, table_names=(\"performance_plot_PGD-20-8-2_table\", \"loss_plot_PGD-20-8-2_table\")\n",
    "    )\n",
    "    #%%\n",
    "    fe_data_np = match_fixed_expert_accuracies(num_experts_list, fe_accs_list)\n",
    "    fe_data_robust_np = match_fixed_expert_accuracies(num_experts_list, fe_accs_robust_list)\n",
    "    #%%\n",
    "    accs_robust_np = np.array(\n",
    "        [accs_robust_list[num_experts_list.index(x)] for x in fe_data_robust_np[:, 0]]\n",
    "    )\n",
    "    accs_robust_up = fe_data_robust_np[:, 1] >= accs_robust_np\n",
    "    fe_data_robust_up = fe_data_robust_np[accs_robust_up]\n",
    "    fe_data_robust_down = fe_data_robust_np[~accs_robust_up]\n",
    "\n",
    "    fe_data_up = fe_data_np[accs_robust_up]\n",
    "    fe_data_down = fe_data_np[~accs_robust_up]\n",
    "\n",
    "    #%%\n",
    "    plot_fixed_experts(\n",
    "        num_experts_list,\n",
    "        accs_robust_list,\n",
    "        fe_data_robust_up,\n",
    "        fe_data_brown_np=fe_data_robust_down,\n",
    "        show_fe_scatter=True,\n",
    "        show_sota=False,\n",
    "        baseline=baseline_attacked,\n",
    "    )\n",
    "    plt.savefig(f\"{figure_prefix}_adv_fixed_expert_plot.png\")\n",
    "    plt.show()\n",
    "\n",
    "    plot_fixed_experts(\n",
    "        num_experts_list,\n",
    "        accs_list,\n",
    "        fe_data_up,\n",
    "        fe_data_brown_np=fe_data_down,\n",
    "        show_fe_scatter=True,\n",
    "        show_sota=False,\n",
    "        ylabel=\"Accuracy\",\n",
    "        baseline=baseline_natural,\n",
    "    )\n",
    "    plt.savefig(f\"{figure_prefix}_natural_fixed_expert_plot.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_runs: List[wandb.wandb_sdk.wandb_run.Run] = api.runs(\"ditschuk/robust-cifar100-resnet-moe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def select(names, tag, run):\n",
    "    return run.name in names and tag in run.tags\n",
    "\n",
    "\n",
    "def filter_sorted(names, tag):\n",
    "    runs = {run.name: run for run in filter(partial(select, names, tag), all_runs)}\n",
    "    return [runs[name] for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_experts_list = [2, 4, 8, 16, 32]\n",
    "run_names = [f\"evaluate-cifar100-resnet18-block-moe{ne}-CGARN-1\" for ne in num_experts_list]\n",
    "for tag in (\"entropy\", \"switch\"):\n",
    "    natural_runs = filter_sorted(run_names, tag)\n",
    "    figure_prefix = f\"fixed_expert_plots/cifar_{tag}\"\n",
    "    fixed_expert_performance_plots(\n",
    "        natural_runs, figure_prefix, baseline_natural=0.7301, baseline_attacked=1e-4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "robust_run_names = [\n",
    "    f\"evaluate-cifar100-resnet18-pgd-adv-train-block-moe{ne}-CGARN-1\" for ne in num_experts_list\n",
    "]\n",
    "for tag in (\"entropy\", \"switch\"):\n",
    "    robust_runs = filter_sorted(robust_run_names, tag)\n",
    "    figure_prefix = f\"fixed_expert_plots/cifar_robust_{tag}\"\n",
    "    fixed_expert_performance_plots(\n",
    "        robust_runs, figure_prefix, baseline_natural=0.5232, baseline_attacked=0.178\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "runs = get_runs(project=\"robust-cifar100-resnet-moe\", tags={\"adv-train-ablation\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_name(name):\n",
    "    if \"pgd\" in name:\n",
    "        return \"PGD-7\"\n",
    "    if \"fast\" in name:\n",
    "        return \"Fast\"\n",
    "    if \"free\" in name:\n",
    "        return \"Free\"\n",
    "\n",
    "\n",
    "names = [run.name for run in runs]\n",
    "adversarial_methods = [parse_name(name) for name in names]\n",
    "architectures = [\n",
    "    \"ResNetBlockMoe\" if \"model.model.num_experts\" in run.config else \"ResNet-18\" for run in runs\n",
    "]\n",
    "accs = [run.summary[\"test/acc\"] for run in runs]\n",
    "adv_accs = [run.summary[\"attack/acc\"] for run in runs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = zip(adversarial_methods, architectures, accs, adv_accs)\n",
    "data = sorted(data, key=lambda o: o[0])\n",
    "data = sorted(data, key=lambda o: o[1])\n",
    "columns = [\"Adversarial Training Method\", \"Architecture\", \"Accuracy\", \"Accuracy against PGD\"]\n",
    "df = pd.DataFrame(\n",
    "    data=data,\n",
    "    # index=index,\n",
    "    columns=columns,\n",
    ")\n",
    "print(df.to_latex(escape=False, na_rep=\"\", index=False))\n",
    "\n",
    "# print(df.to_latex(escape=False, na_rep=\"\", index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "runs = get_runs(project=\"robust-cifar100-resnet-moe\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (robust-sparse-moes)",
   "language": "python",
   "name": "pycharm-5ba1a65f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
